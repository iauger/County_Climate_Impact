{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268141d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iauge\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\auth\\_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# Base data directory\n",
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_dtypes = {\n",
    "    \"geo_id\": str,\n",
    "    \"year\": int,\n",
    "    \"median_income\": float,\n",
    "    \"total_pop\": int,\n",
    "    \"median_age\": float,\n",
    "    \"white_pop\": float,\n",
    "    \"black_pop\": float,\n",
    "    \"hispanic_pop\": float,\n",
    "    \"asian_pop\": float,\n",
    "    \"bachelors_degree_or_higher_25_64\": float,\n",
    "    \"less_than_high_school_graduate\": float,\n",
    "    \"some_college_and_associates_degree\": float,\n",
    "    \"percent_income_spent_on_rent\": float,\n",
    "    \"different_house_year_ago_same_city\": float,\n",
    "    \"different_house_year_ago_different_city\": float,\n",
    "    \"median_rent\": float,\n",
    "    \"rent_over_50_percent\": float,    \n",
    "    \"poverty\": float,\n",
    "    \"gini_index\": float\n",
    "}\n",
    "\n",
    "acs_df = pd.read_csv(DATA_DIR / \"acs_multi_year_panel.csv\", dtype=acs_dtypes)\n",
    "\n",
    "# Sanity check FIPS formatting\n",
    "acs_df[\"geo_id\"] = acs_df[\"geo_id\"].str.zfill(5)\n",
    "\n",
    "# Drop nulls in income (2 rows)\n",
    "acs_df = acs_df.dropna(subset=[\"median_income\"])\n",
    "\n",
    "# Fill minor gaps with  less than 10 nulls\n",
    "minor_cols = [\"median_rent\", \"percent_income_spent_on_rent\", \"rent_over_50_percent\", \"poverty\", \"gini_index\"]\n",
    "acs_df[minor_cols] = acs_df[minor_cols].fillna(acs_df[minor_cols].median())\n",
    "\n",
    "acs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dtypes = {\n",
    "    \"station_id\": str,\n",
    "    \"year\": int,\n",
    "    \"quarter\": int,\n",
    "    \"avg_temp\": float,\n",
    "    \"max_temp\": float,\n",
    "    \"total_precip\": float,\n",
    "    \"heat_days_90F\": int,\n",
    "    \"hail_days\": int,\n",
    "    \"thunder_days\": int,\n",
    "    \"tornado_days\": int,\n",
    "    \"num_days\": int\n",
    "}\n",
    "\n",
    "# Load GSOD aggregates\n",
    "weather_df = pd.read_csv(DATA_DIR / \"gsod_quarterly_aggregates.csv\", dtype=weather_dtypes)\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dtype = {\n",
    "    \"usaf\": str,\n",
    "    \"wban\": str,\n",
    "    \"name\": str,\n",
    "    \"country\": str,\n",
    "    \"state\": str,\n",
    "    \"lat\": float,\n",
    "    \"lon\": float,\n",
    "    \"elev\": str  # keep as str to preserve sign and format\n",
    "    }\n",
    "\n",
    "# Load file\n",
    "stations_df = pd.read_csv(\n",
    "    DATA_DIR / \"noaa_stations.csv\",\n",
    "    dtype=station_dtype,\n",
    "    parse_dates=[\"begin\", \"end\"]\n",
    ")\n",
    "\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0237e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded storm event data: (330416, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>event_type</th>\n",
       "      <th>num_events</th>\n",
       "      <th>total_property_damage</th>\n",
       "      <th>total_crop_damage</th>\n",
       "      <th>total_injuries</th>\n",
       "      <th>total_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33007</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>debris flow</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>debris flow</td>\n",
       "      <td>1</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51009</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>dust devil</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32031</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>dust devil</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21015</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>flash flood</td>\n",
       "      <td>3</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo_id  year  quarter   event_type  num_events  total_property_damage  \\\n",
       "0  33007  2000        2  debris flow           1                    0.0   \n",
       "1  36001  2000        2  debris flow           1               500000.0   \n",
       "2  51009  2000        1   dust devil           1                 3000.0   \n",
       "3  32031  2000        3   dust devil           1                 1000.0   \n",
       "4  21015  2000        1  flash flood           3                25000.0   \n",
       "\n",
       "   total_crop_damage  total_injuries  total_deaths  \n",
       "0                0.0               0             0  \n",
       "1                0.0               0             0  \n",
       "2                0.0               0             0  \n",
       "3                0.0               0             0  \n",
       "4                0.0               0             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_dtypes = {\n",
    "    \"geo_id\": str,\n",
    "    \"year\": int,\n",
    "    \"quarter\": int,\n",
    "    \"event_type\": str,\n",
    "    \"num_events\": int,\n",
    "    \"total_property_damage\": float,\n",
    "    \"total_crop_damage\": float,\n",
    "    \"total_injuries\": int,\n",
    "    \"total_deaths\": int\n",
    "}\n",
    "\n",
    "storm_df = pd.read_csv(DATA_DIR / \"storm_events_by_county_quarter.csv\", dtype=storm_dtypes)\n",
    "\n",
    "print(\"✅ Loaded storm event data:\", storm_df.shape)\n",
    "storm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb1772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13065</td>\n",
       "      <td>Clinch</td>\n",
       "      <td>13</td>\n",
       "      <td>065</td>\n",
       "      <td>POLYGON ((-82.9705 30.94981, -82.97125 31.1839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21083</td>\n",
       "      <td>Graves</td>\n",
       "      <td>21</td>\n",
       "      <td>083</td>\n",
       "      <td>POLYGON ((-88.81724 36.76775, -88.81323 36.773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37177</td>\n",
       "      <td>Tyrrell</td>\n",
       "      <td>37</td>\n",
       "      <td>177</td>\n",
       "      <td>POLYGON ((-76.4056 35.78629, -76.35367 35.8613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38013</td>\n",
       "      <td>Burke</td>\n",
       "      <td>38</td>\n",
       "      <td>013</td>\n",
       "      <td>POLYGON ((-102.93896 48.99928, -102.67765 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40059</td>\n",
       "      <td>Harper</td>\n",
       "      <td>40</td>\n",
       "      <td>059</td>\n",
       "      <td>POLYGON ((-100.00371 36.79697, -100.00256 37.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo_id     NAME STATEFP COUNTYFP  \\\n",
       "0  13065   Clinch      13      065   \n",
       "1  21083   Graves      21      083   \n",
       "2  37177  Tyrrell      37      177   \n",
       "3  38013    Burke      38      013   \n",
       "4  40059   Harper      40      059   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-82.9705 30.94981, -82.97125 31.1839...  \n",
       "1  POLYGON ((-88.81724 36.76775, -88.81323 36.773...  \n",
       "2  POLYGON ((-76.4056 35.78629, -76.35367 35.8613...  \n",
       "3  POLYGON ((-102.93896 48.99928, -102.67765 48.9...  \n",
       "4  POLYGON ((-100.00371 36.79697, -100.00256 37.0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties = gpd.read_file(r\"cb_2023_us_county_5m\\cb_2023_us_county_5m.shp\")\n",
    "\n",
    "# Project to WGS84 (matches lat/lon)\n",
    "counties = counties.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Create a unique FIPS code for join\n",
    "counties[\"geo_id\"] = counties[\"STATEFP\"] + counties[\"COUNTYFP\"]\n",
    "\n",
    "# Select relevant columns\n",
    "counties = counties[[\"geo_id\", \"NAME\", \"STATEFP\", \"COUNTYFP\", \"geometry\"]]\n",
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84aa70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stations_df to a GeoDataFrame\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations_df,\n",
    "    geometry=gpd.points_from_xy(stations_df[\"lon\"], stations_df[\"lat\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Perform spatial join (retains station geometry by default)\n",
    "joined = gpd.sjoin(\n",
    "    stations_gdf,\n",
    "    counties[[\"geo_id\", \"NAME\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "# Rename county geometry to keep it\n",
    "joined = joined.rename(columns={\"geometry\": \"station_geometry\", \"NAME\": \"county_name\"})\n",
    "\n",
    "# Add back county geometry explicitly\n",
    "joined = joined.merge(\n",
    "    counties[[\"geo_id\", \"geometry\"]].rename(columns={\"geometry\": \"county_geometry\"}),\n",
    "    on=\"geo_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep what's relevant, now with county geometry\n",
    "stations_with_fips = gpd.GeoDataFrame(\n",
    "    joined[[\"station_id\", \"geo_id\", \"county_name\", \"lat\", \"lon\", \"county_geometry\"]],\n",
    "    geometry=\"county_geometry\",\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Filter out non-US stations\n",
    "weather_df = weather_df[weather_df[\"station_id\"].isin(stations_with_fips[\"station_id\"])]\n",
    "\n",
    "# Merge Weather and Station data to eventually merge with ACS data\n",
    "weather_df = weather_df.merge(stations_with_fips[[\"station_id\", \"geo_id\", \"county_name\", \"county_geometry\"]], on=\"station_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88518f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_storm_events_by_type(\n",
    "    storm_df: pd.DataFrame,\n",
    "    top_n: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    storm_df = storm_df.copy()\n",
    "    metrics = [\n",
    "        \"num_events\",\n",
    "        \"total_injuries\",\n",
    "        \"total_deaths\",\n",
    "        \"total_property_damage\",\n",
    "        \"total_crop_damage\"\n",
    "    ]\n",
    "\n",
    "    storm_df[metrics] = storm_df[metrics].fillna(0)\n",
    "\n",
    "    # Auto-select most impactful event types\n",
    "    if top_n is not None:\n",
    "        summary = storm_df.groupby(\"event_type\").agg(\n",
    "            total_deaths=(\"total_deaths\", \"sum\"),\n",
    "            total_damage=(\"total_property_damage\", \"sum\")\n",
    "        )\n",
    "        summary[\"combined_impact\"] = summary[\"total_deaths\"] + (summary[\"total_damage\"] / 1_000_000)  # scale damage\n",
    "        top_event_types = summary.sort_values(by=\"combined_impact\", ascending=False).head(top_n).index.tolist()\n",
    "        storm_df = storm_df[storm_df[\"event_type\"].isin(top_event_types)]\n",
    "\n",
    "    # Pivot the filtered data\n",
    "    pivot = storm_df.pivot_table(\n",
    "        index=[\"geo_id\", \"year\", \"quarter\"],\n",
    "        columns=\"event_type\",\n",
    "        values=metrics,\n",
    "        aggfunc=\"sum\",\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    pivot.columns = [\n",
    "        f\"{metric}_{event_type.replace(' ', '_').lower()}\"\n",
    "        for metric, event_type in pivot.columns\n",
    "    ]\n",
    "\n",
    "    return pivot.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2b6578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['geo_id', 'year', 'quarter', 'num_events_debris_flow',\n",
      "       'num_events_flash_flood', 'num_events_flood', 'num_events_hail',\n",
      "       'num_events_heavy_rain', 'num_events_lightning',\n",
      "       'num_events_rip_current', 'num_events_thunderstorm_wind',\n",
      "       'num_events_tornado', 'num_events_wildfire',\n",
      "       'total_crop_damage_debris_flow', 'total_crop_damage_flash_flood',\n",
      "       'total_crop_damage_flood', 'total_crop_damage_hail',\n",
      "       'total_crop_damage_heavy_rain', 'total_crop_damage_lightning',\n",
      "       'total_crop_damage_rip_current', 'total_crop_damage_thunderstorm_wind',\n",
      "       'total_crop_damage_tornado', 'total_crop_damage_wildfire',\n",
      "       'total_deaths_debris_flow', 'total_deaths_flash_flood',\n",
      "       'total_deaths_flood', 'total_deaths_hail', 'total_deaths_heavy_rain',\n",
      "       'total_deaths_lightning', 'total_deaths_rip_current',\n",
      "       'total_deaths_thunderstorm_wind', 'total_deaths_tornado',\n",
      "       'total_deaths_wildfire', 'total_injuries_debris_flow',\n",
      "       'total_injuries_flash_flood', 'total_injuries_flood',\n",
      "       'total_injuries_hail', 'total_injuries_heavy_rain',\n",
      "       'total_injuries_lightning', 'total_injuries_rip_current',\n",
      "       'total_injuries_thunderstorm_wind', 'total_injuries_tornado',\n",
      "       'total_injuries_wildfire', 'total_property_damage_debris_flow',\n",
      "       'total_property_damage_flash_flood', 'total_property_damage_flood',\n",
      "       'total_property_damage_hail', 'total_property_damage_heavy_rain',\n",
      "       'total_property_damage_lightning', 'total_property_damage_rip_current',\n",
      "       'total_property_damage_thunderstorm_wind',\n",
      "       'total_property_damage_tornado', 'total_property_damage_wildfire'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Run severe weather data through function to flatten data and highlight most impactful events\n",
    "storm_wide = pivot_storm_events_by_type(storm_df, top_n=10)\n",
    "print(storm_wide.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c9604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>county_name</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>county_geometry</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>total_precip</th>\n",
       "      <th>heat_days_90F</th>\n",
       "      <th>hail_days</th>\n",
       "      <th>thunder_days</th>\n",
       "      <th>tornado_days</th>\n",
       "      <th>reporting_stations</th>\n",
       "      <th>total_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "      <td>78.274468</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "      <td>79.402209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.665</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "      <td>58.596920</td>\n",
       "      <td>89.6</td>\n",
       "      <td>4.635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "      <td>53.967616</td>\n",
       "      <td>82.8</td>\n",
       "      <td>4.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "      <td>71.111974</td>\n",
       "      <td>95.2</td>\n",
       "      <td>5.695</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>74.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo_id county_name  year  quarter  \\\n",
       "0  01003     Baldwin  2006        2   \n",
       "1  01003     Baldwin  2006        3   \n",
       "2  01003     Baldwin  2006        4   \n",
       "3  01003     Baldwin  2007        1   \n",
       "4  01003     Baldwin  2007        2   \n",
       "\n",
       "                                     county_geometry   avg_temp  max_temp  \\\n",
       "0  POLYGON ((-88.02927 30.22271, -88.02399 30.230...  78.274468      96.8   \n",
       "1  POLYGON ((-88.02927 30.22271, -88.02399 30.230...  79.402209      95.0   \n",
       "2  POLYGON ((-88.02927 30.22271, -88.02399 30.230...  58.596920      89.6   \n",
       "3  POLYGON ((-88.02927 30.22271, -88.02399 30.230...  53.967616      82.8   \n",
       "4  POLYGON ((-88.02927 30.22271, -88.02399 30.230...  71.111974      95.2   \n",
       "\n",
       "   total_precip  heat_days_90F  hail_days  thunder_days  tornado_days  \\\n",
       "0         0.000           16.0        0.0           0.0           0.0   \n",
       "1         5.665           22.0        0.0           3.0           0.0   \n",
       "2         4.635            0.0        0.0           0.0           0.0   \n",
       "3         4.005            0.0        0.0           0.0           0.0   \n",
       "4         5.695            6.5        0.0           0.0           0.0   \n",
       "\n",
       "   reporting_stations  total_days  \n",
       "0                   1        47.0  \n",
       "1                   2        63.0  \n",
       "2                   2        80.5  \n",
       "3                   2        76.0  \n",
       "4                   2        74.5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate station data by county to merge with ACS data\n",
    "county_weather = weather_df.groupby([\"geo_id\", \"county_name\", \"year\", \"quarter\", \"county_geometry\"]).agg(\n",
    "    avg_temp=(\"avg_temp\", \"mean\"),\n",
    "    max_temp=(\"max_temp\", \"max\"),\n",
    "    total_precip=(\"total_precip\", \"mean\"),\n",
    "    heat_days_90F=(\"heat_days_90F\", \"mean\"),\n",
    "    hail_days=(\"hail_days\", \"mean\"),\n",
    "    thunder_days=(\"thunder_days\", \"mean\"),\n",
    "    tornado_days=(\"tornado_days\", \"mean\"),\n",
    "    reporting_stations=(\"station_id\", \"nunique\"),\n",
    "    total_days=(\"num_days\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "county_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bb480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (142272, 84)\n",
      "Training shape: (66600, 84)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142272 entries, 0 to 142271\n",
      "Data columns (total 84 columns):\n",
      " #   Column                                   Non-Null Count   Dtype   \n",
      "---  ------                                   --------------   -----   \n",
      " 0   geo_id                                   142272 non-null  object  \n",
      " 1   county_name                              142272 non-null  object  \n",
      " 2   year                                     142272 non-null  int64   \n",
      " 3   quarter                                  142272 non-null  int64   \n",
      " 4   county_geometry                          142272 non-null  geometry\n",
      " 5   avg_temp                                 142272 non-null  float64 \n",
      " 6   max_temp                                 142272 non-null  float64 \n",
      " 7   total_precip                             142272 non-null  float64 \n",
      " 8   heat_days_90F                            142272 non-null  float64 \n",
      " 9   hail_days                                142272 non-null  float64 \n",
      " 10  thunder_days                             142272 non-null  float64 \n",
      " 11  tornado_days                             142272 non-null  float64 \n",
      " 12  reporting_stations                       142272 non-null  int64   \n",
      " 13  total_days                               142272 non-null  float64 \n",
      " 14  state_fips                               66600 non-null   float64 \n",
      " 15  county_fips                              66600 non-null   float64 \n",
      " 16  median_income                            66600 non-null   float64 \n",
      " 17  total_pop                                142272 non-null  float64 \n",
      " 18  median_age                               66600 non-null   float64 \n",
      " 19  white_pop                                66600 non-null   float64 \n",
      " 20  black_pop                                66600 non-null   float64 \n",
      " 21  hispanic_pop                             66600 non-null   float64 \n",
      " 22  asian_pop                                66600 non-null   float64 \n",
      " 23  bachelors_degree_or_higher_25_64         66600 non-null   float64 \n",
      " 24  less_than_high_school_graduate           66441 non-null   float64 \n",
      " 25  some_college_and_associates_degree       66441 non-null   float64 \n",
      " 26  different_house_year_ago_same_city       66441 non-null   float64 \n",
      " 27  different_house_year_ago_different_city  66441 non-null   float64 \n",
      " 28  median_rent                              66600 non-null   float64 \n",
      " 29  percent_income_spent_on_rent             66600 non-null   float64 \n",
      " 30  rent_over_50_percent                     66600 non-null   float64 \n",
      " 31  poverty                                  66600 non-null   float64 \n",
      " 32  gini_index                               66600 non-null   float64 \n",
      " 33  num_events_debris_flow                   142272 non-null  float64 \n",
      " 34  num_events_flash_flood                   142272 non-null  float64 \n",
      " 35  num_events_flood                         142272 non-null  float64 \n",
      " 36  num_events_hail                          142272 non-null  float64 \n",
      " 37  num_events_heavy_rain                    142272 non-null  float64 \n",
      " 38  num_events_lightning                     142272 non-null  float64 \n",
      " 39  num_events_rip_current                   142272 non-null  float64 \n",
      " 40  num_events_thunderstorm_wind             142272 non-null  float64 \n",
      " 41  num_events_tornado                       142272 non-null  float64 \n",
      " 42  num_events_wildfire                      142272 non-null  float64 \n",
      " 43  total_crop_damage_debris_flow            142272 non-null  float64 \n",
      " 44  total_crop_damage_flash_flood            142272 non-null  float64 \n",
      " 45  total_crop_damage_flood                  142272 non-null  float64 \n",
      " 46  total_crop_damage_hail                   142272 non-null  float64 \n",
      " 47  total_crop_damage_heavy_rain             142272 non-null  float64 \n",
      " 48  total_crop_damage_lightning              142272 non-null  float64 \n",
      " 49  total_crop_damage_rip_current            142272 non-null  float64 \n",
      " 50  total_crop_damage_thunderstorm_wind      142272 non-null  float64 \n",
      " 51  total_crop_damage_tornado                142272 non-null  float64 \n",
      " 52  total_crop_damage_wildfire               142272 non-null  float64 \n",
      " 53  total_deaths_debris_flow                 142272 non-null  float64 \n",
      " 54  total_deaths_flash_flood                 142272 non-null  float64 \n",
      " 55  total_deaths_flood                       142272 non-null  float64 \n",
      " 56  total_deaths_hail                        142272 non-null  float64 \n",
      " 57  total_deaths_heavy_rain                  142272 non-null  float64 \n",
      " 58  total_deaths_lightning                   142272 non-null  float64 \n",
      " 59  total_deaths_rip_current                 142272 non-null  float64 \n",
      " 60  total_deaths_thunderstorm_wind           142272 non-null  float64 \n",
      " 61  total_deaths_tornado                     142272 non-null  float64 \n",
      " 62  total_deaths_wildfire                    142272 non-null  float64 \n",
      " 63  total_injuries_debris_flow               142272 non-null  float64 \n",
      " 64  total_injuries_flash_flood               142272 non-null  float64 \n",
      " 65  total_injuries_flood                     142272 non-null  float64 \n",
      " 66  total_injuries_hail                      142272 non-null  float64 \n",
      " 67  total_injuries_heavy_rain                142272 non-null  float64 \n",
      " 68  total_injuries_lightning                 142272 non-null  float64 \n",
      " 69  total_injuries_rip_current               142272 non-null  float64 \n",
      " 70  total_injuries_thunderstorm_wind         142272 non-null  float64 \n",
      " 71  total_injuries_tornado                   142272 non-null  float64 \n",
      " 72  total_injuries_wildfire                  142272 non-null  float64 \n",
      " 73  total_property_damage_debris_flow        142272 non-null  float64 \n",
      " 74  total_property_damage_flash_flood        142272 non-null  float64 \n",
      " 75  total_property_damage_flood              142272 non-null  float64 \n",
      " 76  total_property_damage_hail               142272 non-null  float64 \n",
      " 77  total_property_damage_heavy_rain         142272 non-null  float64 \n",
      " 78  total_property_damage_lightning          142272 non-null  float64 \n",
      " 79  total_property_damage_rip_current        142272 non-null  float64 \n",
      " 80  total_property_damage_thunderstorm_wind  142272 non-null  float64 \n",
      " 81  total_property_damage_tornado            142272 non-null  float64 \n",
      " 82  total_property_damage_wildfire           142272 non-null  float64 \n",
      " 83  has_acs                                  142272 non-null  int64   \n",
      "dtypes: float64(77), geometry(1), int64(4), object(2)\n",
      "memory usage: 91.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge ACS data with county level quarterly weather data\n",
    "weather_with_acs = county_weather.merge(\n",
    "    acs_df,\n",
    "    on=[\"geo_id\", \"year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Include severe weather data with the merged df\n",
    "weather_with_acs = weather_with_acs.merge(storm_wide, on=[\"geo_id\", \"year\", \"quarter\"], how=\"left\")\n",
    "\n",
    "# Fill storm-related NaNs with 0\n",
    "storm_cols = [col for col in weather_with_acs.columns if \"total_\" in col or \"num_events\" in col] # TODO fix total_pop fill\n",
    "weather_with_acs[storm_cols] = weather_with_acs[storm_cols].fillna(0)\n",
    "\n",
    "# Flag for downstream modeling since we have more  weather data than acs data currently\n",
    "weather_with_acs[\"has_acs\"] = weather_with_acs[\"median_income\"].notna().astype(int)\n",
    "\n",
    "# Training only subset\n",
    "training_data = weather_with_acs[weather_with_acs[\"has_acs\"] == 1].copy()\n",
    "training_data.to_csv(DATA_DIR / \"county_weather_acs_training.csv\", index=False)\n",
    "\n",
    "# Store complete dataset including nulls\n",
    "weather_with_acs.to_csv(DATA_DIR / \"county_weather_acs_complete.csv\", index=False)\n",
    "\n",
    "print(\"Merged shape:\", weather_with_acs.shape)\n",
    "print(\"Training shape:\", training_data.shape)\n",
    "print(weather_with_acs.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
